ransha
Ran Shaham (203781000)
EX: 4

FILES:
README			-- This file
Makefile		-- No arguments creates the CachingFileSystem object
				make tar creates the tar file.
CachingFileSystem.cpp	-- The implementation of all filesystem functions.
Cache.h			-- decleration and implementation of the caching
				algorithm.

REMARKS:
* The filesystem logic and caching logic are as separated as I could manage.
* In the Cache.h file, I defined a Block object which holds all the data
  I needed for blocks in thie ex. Note that upon construction, it allocates
  aligned memory block, which is freed upon object destruction.
* The Block object also have move logic, to prevent multiple allocations for
  the same block of data. That is, when a block is passed by value, it is
  copied using the move ctor which steals its data and does not allocate any
  new data - making it much more efficient.
* The log file is written using std::ofstream object, which is kept as a 
  data member of the CachingState object (the private_data of fuse).
* The Block size is determined in the main function, and saved as a static
  data member of the Block class, making it availabe all over the program.
* The cache data structure is also defined as a static global variable.


ANSWERS:

Q1:
The heap memory segment is (just as other memory segments of the process)
given by a virtual memory address, in a space much bigger (usually) than
the available physical memory. Thus, the OS can save the block (page) in
which the heap is stored - and the 'cached' data with it - to the disk.
This may happen if the cache is very big, the memory is small, or the system
is overloaded with memory consuming processes, making a cache hit even less
efficient than a regular read from the disk, since iterating over all cached
blocks may be involving reading from the disk.

tl;dr - no, this method is not always faster than regular disk access.

Q2:
The problem with implementing sophisticated page swapping algorithms is that
when reading/writing pages from/to the disk directly, the OS is occupied by
that operation, and can't handle other request in the meantime. Therefore
there is a need in serious page faults minimization which will yield more
complicated algorithms. Instead, the OS can use a DMA controller, which will
handle the page swapping, and continue to perform other tasks.

Q3:
__ LRU > LFU __
Consider the following case - reading the same two files a lot of times, and
then moving to handle (only) other files in no particular order.
The LFU will bring the blocks of the first 2 files to the cache, and because
of their high reference count they will be stuck there for a long time, even
though they aren't needed anymore. In contrast, the LRU will cache only the
data that is recently accessed (more precisely, evict the LRU blocks) thus
will be quick to forget those first 2 files, leaving room for other relevant
data.

__ LFU > LRU __
Consider a program that maintains a log file (or some constant set of files),
while handling other files and data at the same time. The log is accessed all
the time, therefore shouldn't be evicted when handling other files, but the
LRU will do just that - it does not remember the file's high usage, whereas
the LFU will handle this situation better.

__ {LFU,LRU} == :-( __
A program that searches for a file in a very large files pool by iterating
over it will fail both algorithms. The LFU will fail because every file is
accessed exactly once, thus the replacement rule is meaningless. The LRU will
fail for the same reason - A recent block won't be accessed again so keeping
it in the cache is a waste.
For this case, an algorithm that maximizes spatial locality will do better,
assuming the iteration is in some reasonable order.

Q4:
Not-increasing the refCount in the new section attempts to solve the problem
of blocks being referenced a lot in a very short time - due to temporal
locality - and are unneeded after that short period. In this case, this
blocks' refCount may be very high and therefore won't be evicted, although
they are not used anymore, whereas blocks that are referenced less but more
constantly will be evicted in their place even though they shouldn't.
Defining the new section tries to solve that problem.

